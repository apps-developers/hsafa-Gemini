---
title: Distributed Agent Platform Architecture
description: Building an Agent Builder + Distributed Agent Runtime (gateway) that scales into an agentic network (SmartSpaces + Entities) with persistent memory and distributed tool execution.
---

# üß† The Big Idea

You are building an **Agent Builder + Distributed Agent Runtime** that can grow into an **agentic system network**.

A system where:

* Users **create agents** via config
* Agents run **on your server** (the gateway is the runtime)
* Any client (web, mobile, node app) can:
  * Start a run
  * Watch it stream
  * Refresh and reconnect
* Agents can call **tools that run anywhere** (server, browser, other devices)

This is like giving AI agents a **backend, memory, and a network of devices**.

The update: instead of thinking only in ‚Äúone agent ‚Üî one chat‚Äù, the platform‚Äôs native model becomes **many Entities collaborating inside shared contexts** (SmartSpaces).

---

# üï∏Ô∏è Agentic Network Model (SmartSpaces + Entities)

## Core primitives

### SmartSpace

A **SmartSpace** is a shared context space (a timeline of events/messages) where participants collaborate.

- A SmartSpace can contain any number of participants.
- SmartSpaces can be public (many participants) or private (small, scoped contexts like ‚ÄúManager SmartSpace‚Äù).

### Entity

An **Entity** is anything that can participate in a SmartSpace.

- **Human Entity** (a user from your app)
- **Agent Entity** (an AI agent)
- **System Entity** (a service/backend/integration/device)

An Agent Entity can belong to multiple SmartSpaces.

### Client

A **Client** is a connection point where streams are delivered and responses are received.

- Examples: web browser, mobile app, Node.js backend, IoT device
- A Client is **not** an Entity ‚Äî it is a delivery channel

One Entity can connect from **multiple Clients** simultaneously. For example, a single Human Entity (user) might be logged in on both web and mobile at the same time. Both Clients receive the same stream; both can send messages as that Entity.

### Run (Agent execution)

A **Run** is one execution of **one Agent Entity** in response to a trigger that occurred inside a specific SmartSpace.

- A single SmartSpace event may trigger multiple Runs (one per Agent Entity in that SmartSpace).
- Each Agent decides whether to respond (an Agent may do work and then emit no user-visible message).

### Step (inside a Run)

Inside a Run, execution is a multi-step reasoning-and-acting loop:

- **Run** = a complete multi-step AI interaction
- **Step** = a single LLM call within that Run

This distinction matters because the gateway streams **partial outputs** (text deltas, tool calls, tool results) while the Run is still in progress.

## Triggers (what starts a Run)

An Agent Entity can be triggered in several ways:

* A Human Entity message inside a SmartSpace
* Its own scheduled Plan (proactive execution)
* Another Agent Entity inside a SmartSpace
* A System Entity event inside a SmartSpace

## Scheduling and long-term behavior

Each Agent Entity maintains:

* **Plan**: schedules future executions (cron-like). Example: ‚Äúsend a reminder at 6 PM‚Äù.
* **Goals**: short-term and long-term objectives that influence decisions over time.

The key design choice: **Plans and Goals are first-class state**, not just prompt text.

---

<details>
<summary>Architecture (later)</summary>

# üèóÔ∏è System Architecture

## 1Ô∏è‚É£ Agent Builder (Control Plane)

Users send agent configs:

```json
{
  "version": "1.0",
  "agent": {
    "name": "research-agent",
    "system": "..."
  },
  "model": {
    "provider": "openai",
    "name": "gpt-4.1-mini"
  },
  "tools": []
}
```

You:

* Store config in **durable storage**
* Reuse config when runs start

---

## 2Ô∏è‚É£ Agent Runtime (Execution Plane)

When a user starts a run:

1. Load agent config
2. Load chat history
3. Start the agent engine (the reasoning + tool loop)
4. Stream output
5. Handle tool calls
6. Save everything

Your system is the **body + memory + network**.

In the SmartSpace model, the gateway runtime expands slightly:

1. A message/event is written to a SmartSpace timeline.
2. The gateway triggers Runs for Agent Entities that belong to that SmartSpace.
3. Each Run streams events (text/tool-calls/tool-results) and may append new messages/events back into the SmartSpace.

---

</details>

# üîÅ Example scenario: Leave Request (Cross-SmartSpace)

A Human Entity asks an Agent Entity (in the Employee SmartSpace) to send a leave request to their manager.

1. The Human posts a message in the **Employee SmartSpace**.
2. All Agent Entities in that SmartSpace are triggered; only the relevant Agent chooses to respond.
3. During the same Run, the Agent calls a tool that triggers a **new Run** of itself inside a different SmartSpace: the **Manager SmartSpace**.
4. The Manager SmartSpace is private and contains only the Manager (Human Entity) and the Agent.
5. The Agent asks the Manager for approval.
6. The Manager replies; that reply becomes a new event in the Manager SmartSpace, triggering the Agent again there.
7. The Agent then triggers another Run back in the Employee SmartSpace to deliver the final decision.

While waiting, if the employee asks for status, the Agent can:

* Read the Manager SmartSpace timeline.
* Summarize progress back in the Employee SmartSpace.

---

# üß∞ Tool Visibility and Interaction

## Tool call visibility modes

When an Agent calls a tool, it can decide **who can see and interact with that tool call**:

### 1. Entity-visible tools

The Agent can mark a tool call as visible to **all Entities** in the SmartSpace. This allows:

- Entities to see the tool call and its parameters
- Entities to provide a response (output) to the tool
- Collaborative workflows where multiple participants interact with the same tool execution

**Use case**: A form tool that a specific user needs to fill out, or a confirmation tool that requires approval.

### 2. Main Tools (internal)

**Main Tools** are internal tools that **no Entity should see or interact with**. These are the Agent's private capabilities for managing its own state and reasoning.

---

# üé® Tool Display Configuration (TODO)

> **Note:** This section describes planned functionality that has not been implemented yet.

## Display Modes

Each tool can be configured with a `display` property that controls how it appears in the chat UI:

```json
{
  "name": "searchDatabase",
  "display": {
    "mode": "full" | "minimal" | "hidden",
    "showInput": true,
    "showOutput": true
  }
}
```

### Display Mode Options

| Mode | Description |
| ---- | ----------- |
| `full` | Show tool call with input and output (based on `showInput`/`showOutput` flags) |
| `minimal` | Only show that the tool was called (name + status indicator, no input/output) |
| `hidden` | Tool call is not shown in the chat UI at all |

### Configuration Examples

```json
// Full display - show everything
{
  "name": "webSearch",
  "display": { "mode": "full", "showInput": true, "showOutput": true }
}

// Show input only (e.g., search query shown, results hidden)
{
  "name": "internalLookup",
  "display": { "mode": "full", "showInput": true, "showOutput": false }
}

// Minimal - only show that tool was called
{
  "name": "updateMemory",
  "display": { "mode": "minimal" }
}

// Hidden - internal tool, never shown
{
  "name": "planManagement",
  "display": { "mode": "hidden" }
}
```

### Default Behavior

- **Entity-visible tools**: Default to `{ mode: "full", showInput: true, showOutput: true }`
- **Main Tools (internal)**: Default to `{ mode: "hidden" }`

---

# üß© Custom Tool UI Components (TODO)

> **Note:** This section describes planned functionality that has not been implemented yet.

Tools can have custom UI components that replace the default tool display. This enables rich, interactive experiences.

## Architecture

The Hsafa stack uses:
- **`@hsafa/react-sdk`** ‚Äî Hooks-only SDK for data fetching (`useSmartSpaceMessages`, `useHsafaClient`, etc.)
- **`@assistant-ui/react`** ‚Äî UI primitives (`MessagePrimitive`, `ThreadPrimitive`, etc.)

Custom tool UIs are registered via `MessagePrimitive.Content` components.

## Registering Custom Tool UIs

### Option 1: Tools() API with Toolkit (Recommended)

The recommended approach is to define tools with their `render` function in a toolkit:

```tsx
import { useAui, Tools, type Toolkit } from "@assistant-ui/react";

const toolkit: Toolkit = {
  webSearch: {
    description: "Search the web",
    parameters: z.object({ query: z.string() }),
    // No execute - tool runs on gateway
    render: ({ args, result, status }) => (
      <SearchResultsCard
        query={args.query}
        results={result?.results}
        loading={status.type === "running"}
      />
    ),
  },
  
  requestApproval: {
    description: "Request user approval",
    parameters: z.object({ title: z.string(), amount: z.number() }),
    // No execute - basic tool, response via addResult
    render: ({ args, result, status, addResult }) => {
      if (result) return <div>{result.approved ? "‚úÖ Approved" : "‚ùå Rejected"}</div>;
      return (
        <div className="rounded border p-4">
          <p>{args.title}: ${args.amount}</p>
          <button onClick={() => addResult({ approved: true })}>Approve</button>
          <button onClick={() => addResult({ approved: false })}>Reject</button>
        </div>
      );
    },
  },
};

// Register in runtime provider
function MyRuntimeProvider({ children }) {
  const runtime = useHsafaRuntime({ /* ... */ });

  const aui = useAui({
    tools: Tools({ toolkit }),
  });

  return (
    <AssistantRuntimeProvider aui={aui} runtime={runtime}>
      {children}
    </AssistantRuntimeProvider>
  );
}
```

### Option 2: Per-Tool Components via MessagePrimitive.Content

For simpler setups or when using `useExternalStoreRuntime`, pass tool components directly:

```tsx
import { MessagePrimitive } from "@assistant-ui/react";

// Custom UI components for specific tools
const toolComponents = {
  webSearch: WebSearchToolUI,
  requestApproval: ApprovalToolUI,
};

function AssistantMessage() {
  return (
    <MessagePrimitive.Root>
      <MessagePrimitive.Content
        components={{
          tools: {
            ...toolComponents,
            Fallback: DefaultToolUI, // fallback for unregistered tools
          },
        }}
      />
    </MessagePrimitive.Root>
  );
}
```

This is what the `nextjs-test-app` currently uses with `useExternalStoreRuntime`.

## Tool UI Component Props

All tool UI components receive:

```tsx
interface ToolUIProps {
  toolName: string;
  toolCallId: string;
  args: Record<string, unknown>;
  argsText: string;                    // JSON stringified args
  result?: unknown;
  status: {
    type: "running" | "complete" | "incomplete" | "requires-action";
    reason?: string;                   // e.g., "error", "cancelled"
  };
  
  // For interactive tools - submit a result back to the gateway
  addResult?: (result: unknown) => void;
}
```

## Custom UI for Basic Tools

For **basic tools** (see [basic-tool.md](/hsafa-tools/basic-tool.md)), custom UIs can return a tool response via `addResult()`:

```tsx
function ApprovalToolUI({ args, result, status, addResult }: ToolUIProps) {
  // Already completed
  if (result) {
    return <div>{result.approved ? "‚úÖ Approved" : "‚ùå Rejected"}</div>;
  }

  // Waiting for user input
  return (
    <div className="rounded border p-4">
      <p>{args.title}</p>
      <div className="flex gap-2 mt-3">
        <button onClick={() => addResult({ approved: true })}>Approve</button>
        <button onClick={() => addResult({ approved: false })}>Reject</button>
      </div>
    </div>
  );
}
```

## Custom UI for Gateway-Executed Tools

Tools that execute on the gateway can still have custom visualization:

```tsx
function DatabaseQueryToolUI({ args, result, status }: ToolUIProps) {
  if (status.type === "running") {
    return <QueryLoadingState query={args.sql} />;
  }
  
  if (status.type === "incomplete" && status.reason === "error") {
    return <ErrorDisplay message="Query failed" />;
  }

  return <DataTable rows={result.rows} columns={result.columns} />;
}
```

## Display Mode + Custom UI Integration

The `display` configuration works with custom UIs:

```json
{
  "name": "webSearch",
  "display": { "mode": "full", "showInput": true, "showOutput": true }
}
```

- If `display.mode` is `"hidden"`, the tool UI is not rendered at all
- If `display.mode` is `"minimal"`, the custom UI receives a hint to render minimally
- If `display.mode` is `"full"`, the custom UI renders fully

The custom UI can check `display` config via props and adjust rendering accordingly.

## Fallback Behavior

If no custom UI is registered for a tool:
1. Check the tool's `display` configuration
2. Render using the default `ToolFallback` component (collapsible with args/result)

```tsx
// Default fallback shows tool name, status, and expandable args/result
function DefaultToolUI({ toolName, args, status }: ToolUIProps) {
  const isRunning = status.type === "running";
  return (
    <div className="flex items-center gap-2 rounded border px-2 py-1 text-xs">
      {isRunning ? <LoaderIcon className="animate-spin" /> : <CheckIcon />}
      <span>{isRunning ? "Running" : "Completed"} {toolName}</span>
    </div>
  );
}
```

---

# üß∞ Main Tools every Agent Entity should have

These are internal tools that Entities do not see or interact with:

1. **Plan management tools**

   * Update its schedule (Plan)
   * Read its scheduled actions

2. **Goal management tools**

   * Update its Goals
   * Read its Goals

3. **Memory tools**

   * Store long-term facts, user preferences, learnings
   * Retrieve memories by topic or Entity
   * Memory persists across Runs and SmartSpaces

4. **SmartSpace awareness tools**

   * Read the list of SmartSpaces it belongs to
   * Read messages/events from a specific SmartSpace

5. **Entity awareness tools**

   * List Entities in a SmartSpace
   * Look up Entity info (who is this person, what are their preferences)

6. **Cross-SmartSpace execution tool**

   * Run itself as a new execution inside a specific SmartSpace
   * Include instructions about what it should do there
   * Include context about where the run originated
   * This also enables agent-to-agent collaboration: create a private SmartSpace between two agents, then run there to communicate

7. **SmartSpace management tools**

   * Create SmartSpaces
   * Delete SmartSpaces

8. **Time awareness tools**

   * Get current time
   * Understand how long ago events happened
   * Reason about deadlines and urgency

9. **Self-reflection tools**

   * Read its own past Runs
   * Summarize what it learned or did wrong
   * Track patterns in its behavior
